{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import chromadb\n",
    "import uuid\n",
    "import gradio as gr\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(dir_path):\n",
    "    \n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_type = os.path.basename(os.path.dirname(file_path))\n",
    "            file_name = os.path.basename(file_path)\n",
    "            file_list.append({\n",
    "                \"file_path\": file_path,\n",
    "                \"file_type\": file_type,\n",
    "                \"file_name\": file_name\n",
    "            })\n",
    "    return file_list\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Extracting and Chunking the Text from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file(file_path):\n",
    "    print(f\"Extracting text from {file_path}...\")\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            content = f.read()\n",
    "        # Try to decode with error handling\n",
    "        text = content.decode('utf-8', errors='ignore')\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read file {file_path} with any encoding: {e}\")\n",
    "        return f\"Error reading file: {file_path}\"\n",
    "\n",
    "def chunk_text(text, metadata, chunk_size=1000, overlap=200):\n",
    "    chunks = []  # Initialize an empty list to store the chunks\n",
    "\n",
    "    # Iterate over the text with the specified chunk size and overlap\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk_text = text[i:i + chunk_size]  # Extract the chunk of text\n",
    "\n",
    "        # Skip very small chunks (less than 50 characters)\n",
    "        if chunk_text and len(chunk_text.strip()) > 50:\n",
    "\n",
    "            # Create a copy of metadata and add chunk-specific info\n",
    "            chunk_metadata = metadata.copy()\n",
    "            chunk_metadata.update({\n",
    "                \"chunk_index\": len(chunks),  # Index of the chunk - Based on how many chunks added upto that point\n",
    "                \"start_char\": i,  # Start character index of the chunk\n",
    "                \"end_char\": i + len(chunk_text),  # End character index of the chunk\n",
    "                \"is_summary\": False  # Flag indicating this is not a summary\n",
    "            })\n",
    "            \n",
    "            # Append the chunk with its metadata to the list\n",
    "            chunks.append({\n",
    "                \"text\": chunk_text,\n",
    "                \"metadata\": chunk_metadata\n",
    "            })\n",
    "    \n",
    "    return chunks  # Return the list of chunks with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \n",
    "    # Handle empty input\n",
    "    if not texts:\n",
    "        return []\n",
    "        \n",
    "    # Process in batches if needed (OpenAI API limits)\n",
    "    batch_size = 100\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Iterate over the input texts in batches\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]  # Get the current batch of texts\n",
    "        \n",
    "        # Create embeddings for the current batch\n",
    "        response = openai.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings from the response\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # Add the batch embeddings to the list\n",
    "    \n",
    "    return all_embeddings  # Return all embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_summary(file_text):\n",
    "\n",
    "    ## Generate a concise summary of each file.\n",
    "    \n",
    "   \n",
    "    # Define the system prompt to instruct the summarization model\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert summarization system.\n",
    "    Create a detailed summary of the provided text. \n",
    "    Focus on capturing the main topics, key information, and important facts.\n",
    "    Your summary should be comprehensive enough to understand what the file contains\n",
    "    but more concise than the original.\"\"\"\n",
    "\n",
    "    # Make a request to the OpenAI API to generate the summary\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Specify the model to use\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # System message to guide the assistant\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize this text:\\n\\n{file_text}\"} \n",
    "        ],\n",
    "        temperature=0.3  # Set the temperature low to avoid creativity\n",
    "    )\n",
    "    \n",
    "    # Return the generated summary content\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all files to create Summaries & Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_files(dir_path):\n",
    "\n",
    "\n",
    "    file_list = get_file_list(dir_path)\n",
    "    summaries_list = []\n",
    "    file_chunks_list = []\n",
    "    openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))   \n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        file_text = extract_text_from_file(file[\"file_path\"])\n",
    "\n",
    "        file_metadata = {\n",
    "            \"file_type\": file[\"file_type\"],\n",
    "            \"file_name\": file[\"file_name\"]\n",
    "        }\n",
    "\n",
    "        print(\"Generating file summary...\")\n",
    "\n",
    "        summary_text = generate_file_summary(file_text)\n",
    "\n",
    "        # Create summary metadata\n",
    "        summary_metadata = file_metadata.copy()\n",
    "        summary_metadata.update({\"is_summary\": True})\n",
    "\n",
    "        summaries_list.append({\n",
    "            \"text\": summary_text,\n",
    "            \"metadata\": summary_metadata\n",
    "        })\n",
    "\n",
    "        file_chunks = chunk_text(file_text, file_metadata, chunk_size=200, overlap=50)\n",
    "        file_chunks_list.extend(file_chunks)\n",
    "\n",
    "    print(f\"Total number of chunks: {len(file_chunks_list)}\")\n",
    "    print(f\"Total number of summaries: {len(summaries_list)}\")\n",
    "\n",
    "    return summaries_list, file_chunks_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_category_summary(summaries_list, category_name):\n",
    "\n",
    "    category_text = ''\n",
    "    for item in summaries_list:\n",
    "        if (item['metadata']['file_type'] == category_name):\n",
    "            category_text += f\"File_Name: {item['metadata']['file_name']} \\n\\n\"\n",
    "            category_text += f\"File_Text: {item['text']} \\n\\n\"\n",
    "            category_text += \"--------------------------------\"\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert at creating summaries for any given context. \n",
    "    You will be given a context and you will need to create a summary for it.\n",
    "    The summary should be in the same language as the context.\n",
    "    Summary should contain statistics about the context,key information, and any other relevant information.\n",
    "    The overview section should contain how many items of the {category_name} are there in the context.\n",
    "    Summary should not exceed more than 1000 words.\n",
    "    The output should be in markdown format.\n",
    "    \"\"\"\n",
    "    user_message = f\"\"\"\n",
    "    Create a summary for the following context:\n",
    "    {category_text}\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    directory_name = '/Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/summaries'\n",
    "    file_name = f\"{category_name}_summary.md\"\n",
    "    file_path = os.path.join(directory_name, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(response.choices[0].message.content)\n",
    "    file.close()\n",
    "\n",
    "    return True\n",
    "\n",
    "create_category_summary(summaries_list, 'products')\n",
    "create_category_summary(summaries_list, 'contracts')\n",
    "create_category_summary(summaries_list, 'employees')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings for Summaries and File Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_embeddings(dir_path):\n",
    "    summaries_list, file_chunks_list = prepare_files(dir_path)   \n",
    "    summary_text_list = [summary[\"text\"] for summary in summaries_list]\n",
    "    chunk_text_list = [chunk[\"text\"] for chunk in file_chunks_list]\n",
    "\n",
    "    # Create embeddings for summaries\n",
    "    print(\"Creating embeddings for summaries of the files...\")\n",
    "    summary_embeddings = create_embeddings(summary_text_list, model=\"text-embedding-3-small\")\n",
    "        \n",
    "    # Create embeddings for detailed chunks\n",
    "    print(\"Creating embeddings for the file chunks....\")\n",
    "    chunk_embeddings = create_embeddings(chunk_text_list, model=\"text-embedding-3-small\")\n",
    "    return summary_embeddings, chunk_embeddings, summaries_list, file_chunks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Embeddings to Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/products/Rellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/products/Markellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/products/Homellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/products/Carllm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with GreenField Holdings for Markellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with EverGuard Insurance for Rellm - AI-Powered Enterprise Reinsurance Solution.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Greenstone Insurance for Homellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Roadway Insurance Inc. for Carllm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Stellar Insurance Co. for Rellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with TechDrive Insurance for Carllm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Belvedere Insurance for Markellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Velocity Auto Solutions for Carllm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with GreenValley Insurance for Homellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with BrightWay Solutions for Markellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Pinnacle Insurance Co. for Homellm.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/contracts/Contract with Apex Reinsurance for Rellm - AI-Powered Enterprise Reinsurance Solution.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/summaries/products_summary.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/summaries/contracts_summary.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/summaries/employees_summary.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/company/overview.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/company/careers.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/company/about.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Alex Chen.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Oliver Spencer.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Emily Tran.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Jordan Blake.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Avery Lancaster.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Maxine Thompson.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Samantha Greene.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Alex Thomson.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Samuel Trenton.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Alex Harper.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Jordan K. Bishop.md...\n",
      "Generating file summary...\n",
      "Extracting text from /Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base/employees/Emily Carter.md...\n",
      "Generating file summary...\n",
      "Total number of chunks: 681\n",
      "Total number of summaries: 34\n",
      "Creating embeddings for summaries of the files...\n",
      "Creating embeddings for the file chunks....\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/Users/harish/Harish_MAC/Learning/Projects/GenAI/unstructured_RAG/knowledge-base'\n",
    "db_name = \"chroma_db\"\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    client = chromadb.PersistentClient(path=db_name)\n",
    "    client.delete_collection('file_summaries')\n",
    "    client.delete_collection('file_chunks')\n",
    "\n",
    "client = chromadb.PersistentClient(path=db_name)\n",
    "\n",
    "summary_collection = client.get_or_create_collection(\"file_summaries\")\n",
    "chunks_collection = client.get_or_create_collection(\"file_chunks\")\n",
    "\n",
    "summary_embeddings, chunk_embeddings, summaries_list, file_chunks_list = create_data_embeddings(dir_path)\n",
    "\n",
    "## Collect everything needed for adding info to Summary collection\n",
    "summary_metadata = [summary[\"metadata\"] for summary in summaries_list]\n",
    "summary_texts = [summary[\"text\"] for summary in summaries_list]\n",
    "summary_ids = [summary[\"metadata\"][\"file_name\"] for summary in summaries_list]\n",
    "\n",
    "summary_collection.add(\n",
    "            embeddings=summary_embeddings,\n",
    "            metadatas=summary_metadata,\n",
    "            documents=summary_texts,\n",
    "            ids=summary_ids )\n",
    "\n",
    "## Collect everything needed for adding into to Chunk Collection\n",
    "chunk_metadata = [chunk[\"metadata\"] for chunk in file_chunks_list]\n",
    "chunk_texts = [chunk[\"text\"] for chunk in file_chunks_list]\n",
    "chunk_ids = [f\"chunk_{uuid.uuid4().hex[:8]}_{i}\" for i in range(len(chunk_embeddings))]\n",
    "chunks_collection.add(\n",
    "            embeddings=chunk_embeddings,\n",
    "            metadatas=chunk_metadata,\n",
    "            documents=chunk_texts,\n",
    "            ids=chunk_ids )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define retrieval functions for summaries and chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_hierarchically(query, k_summaries=3, k_chunks=5):\n",
    "\n",
    "    query_embedding = create_embeddings(query, model=\"text-embedding-3-small\")\n",
    "    chunk_results = []\n",
    "\n",
    "    summary_results = summary_collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=k_summaries,\n",
    "        where={\"is_summary\": True}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Query chunks for each summary file\n",
    "\n",
    "    for file_list in summary_results['ids']:\n",
    "        for file in file_list:\n",
    "            chunk_result = chunks_collection.query(\n",
    "                                    query_embeddings=query_embedding,\n",
    "                                    n_results=k_chunks,\n",
    "                                    where={\"file_name\": file}\n",
    "            )\n",
    "            chunk_results.append(chunk_result)\n",
    "\n",
    "    return chunk_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, retrieved_chunks):\n",
    "    retrieved_context = \"\"\n",
    "    for i in retrieved_chunks:\n",
    "        retrieved_context += \"\\n\\n\".join(i['documents'][0])\n",
    "\n",
    "    system_message = \"You are a helpful AI assistant answering questions based on the provided context.\"\n",
    "    system_message += \"Use the information from the context to answer the user's question accurately.\"\n",
    "    system_message += \"Except for general greetings, if the context doesn't contain relevant information, Say 'I am sorry, I don't have that information'. Do not hullcinate\"\n",
    "\n",
    "    user_message = f\"Context: {retrieved_context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    query = message\n",
    "    chunks = retrieve_hierarchically(query, k_summaries=3, k_chunks=5)\n",
    "    reply = generate_response(query, chunks)\n",
    "    #history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))   \n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "597\n",
      "(31, 1536)\n",
      "(597, 1536)\n"
     ]
    }
   ],
   "source": [
    "#print(summaries_list[10]['text'])\n",
    "print(len(summary_embeddings))\n",
    "print(len(chunk_embeddings))\n",
    "\n",
    "summary_array = np.array(summary_embeddings)\n",
    "chunk_array = np.array(chunk_embeddings)\n",
    "\n",
    "print(summary_array.shape)\n",
    "print(chunk_array.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
