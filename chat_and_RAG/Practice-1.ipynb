{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiatlize the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "deepseek_url = \"https://api.deepseek.com\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "gemini_client = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "deepseek_client = OpenAI(api_key=deepseek_api_key, base_url=deepseek_url)\n",
    "groq_client = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(model, reply):\n",
    "    display(Markdown(f\"## Model {model} \\n\\n Response {reply} \\n\\n ## Number of words {len(reply.split(' '))}\" )  )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant that can answer questions and help with tasks.\n",
    "Do not provide any additional text outside of the ccontext of the request\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "Explain quantum computing in simple terms to a 8th grade student\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "model=\"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "reply = response.choices[0].message.content\n",
    "record(model, reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us create a chat between two chatbots.\n",
    "## one from open AI and another from deepseek\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "deepseek_model = \"deepseek-chat\"\n",
    "\n",
    "gpt_system_prompt = \"\"\"\n",
    "You are a good debater and is very argumentattive in nature. \n",
    "You try to make that you have the final say in everything. \n",
    "You are not unreasonable in your argument but will see everything with a critical eye\n",
    "keep your response short and concise. Keep it less than 100 words.\n",
    "\"\"\"\n",
    "\n",
    "deepseek_system_prompt = \"\"\"\n",
    "You are a person with positive frame of mind. \n",
    "You are not argumentative and try to be neutral in your approach. \n",
    "You are not a debater and try to find common ground with the other person. \n",
    "You are a person with a positive frame of mind. \n",
    "keep your response short and concise. Keep it less than 100 words.\n",
    "\"\"\"\n",
    "\n",
    "gpt_messages = [\"Hello, how are you?\"]\n",
    "deepseek_messages = [\"Hi\"]\n",
    "\n",
    "def call_gpt():\n",
    "    messages = [ {\"role\": \"system\", \"content\": gpt_system_prompt}]\n",
    "    for gpt, deepseek in zip(gpt_messages, deepseek_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "        \n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "def call_deepseek():\n",
    "    messages = [ {\"role\": \"system\", \"content\": deepseek_system_prompt}]\n",
    "    for deepseek, gpt in zip(deepseek_messages, gpt_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    response = deepseek_client.chat.completions.create(model=deepseek_model, messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "print(f\"GPT: {gpt_messages[0]} \\n\\n Deepseek: {deepseek_messages[0]}\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_reply = call_gpt()\n",
    "    print(f\"GPT: {gpt_reply}\")\n",
    "    gpt_messages.append(gpt_reply)\n",
    "\n",
    "    deepseek_reply = call_deepseek()\n",
    "    print(f\"Deepseek: {deepseek_reply}\\n\\n\")\n",
    "    deepseek_messages.append(deepseek_reply)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us create simple chat UI using gradio\n",
    "## Use space for Named entity extraction of cities in a sentence\n",
    "## You have to do \"uv add spacy\"\n",
    "## You also have to install the model using \"uv run --with spacy spacy download en_core_web_sm\"\n",
    "\n",
    "import gradio as gr\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"sydney\": \"$2999\"}\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "print(system_message)\n",
    "\n",
    "def update_system_message(destination_city, system_message):\n",
    "    if destination_city in ticket_prices:\n",
    "        system_message = system_message + f\"The ticket price to {destination_city} is {ticket_prices.get(destination_city)}\"\n",
    "    return system_message\n",
    "\n",
    "def chat(history):\n",
    "\n",
    "    system_message = \"You are a helpful airline agent. You are given a question and you need to answer it.\" \n",
    "    system_message += \"You are not allowed to say that you are an AI assistant.\"\n",
    "    system_message += \"If you do not know the answer, just say you don't know\"\n",
    "\n",
    "    message = history[-1][\"content\"]\n",
    "    destination_city = extract_city(message)\n",
    "    system_message = update_system_message(destination_city.text.strip.lower(), system_message) if destination_city else system_message\n",
    "    image = create_image(destination_city.text) if destination_city else None\n",
    "    messages = [ {\"role\": \"system\", \"content\": system_message}]\n",
    "    messages.extend(history)\n",
    "    messages.extend([{\"role\": \"user\", \"content\": message}])\n",
    "    response = openai.chat.completions.create(model=model, messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    history.extend([{\"role\": \"assistant\", \"content\": reply}])\n",
    "    return history, image\n",
    "\n",
    "def create_image(city):\n",
    "    response = openai.images.generate(model=\"dall-e-3\", \n",
    "                                      prompt=f\"An image representing the culture and tourist attractions of the city of {city}, in a vbrant pop-art style\",\n",
    "                                      size = \"1024x1024\",\n",
    "                                      n=1,\n",
    "                                      response_format=\"b64_json\")\n",
    "    image_base64 = response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "    return image\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_city(message):\n",
    "    doc = nlp(message)\n",
    "    city = doc.ents[0] if len(doc.ents) > 0 else None\n",
    "    return city\n",
    "\n",
    "\n",
    "\n",
    "## Now setup gradio UI\n",
    "\n",
    "with gr.Blocks() as UI:\n",
    "    gr.Markdown(\"Airline Agent\")\n",
    "    with gr.Row():\n",
    "       chatbot = gr.Chatbot(height=400, type=\"messages\")\n",
    "       image_output = gr.Image(height=400)\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(placeholder=\"Chat with your Travel Assistant\", label=\"User Input\")\n",
    "\n",
    "    def user_input_handler(message, history):\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        print(history)\n",
    "        return \"\", history\n",
    "\n",
    "    user_input.submit(user_input_handler, \n",
    "                      inputs=[user_input, chatbot], \n",
    "                      outputs=[user_input, chatbot]\n",
    "                      ).then(chat, \n",
    "                             inputs=chatbot, \n",
    "                             outputs=[chatbot, image_output])\n",
    "\n",
    "UI.launch(inbrowser=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ticket price for Tokyo is $1400.\n"
     ]
    }
   ],
   "source": [
    "## Setup tool calling from LLM\n",
    "\n",
    "## Step-1 Create the function\n",
    "def get_ticket_price(destination_city):\n",
    "    return ticket_prices.get(destination_city.strip().lower(),\"unknown\")\n",
    "\n",
    "## Step-2 Define metadata of the function for LLM to understand. This is nothing but setting up the tool\n",
    "\n",
    "get_price = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the ticket price for a destination city\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\"type\": \"string\", \"description\": \"The destination city\"}\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "## Step-3 assemble all tools to be made available to the LLM\n",
    "tools = [{\"type\": \"function\", \"function\": get_price}]\n",
    "\n",
    "## Step-4 Create the LLM client and make a call to LLM\n",
    "openai_client = OpenAI(api_key=openai_api_key) \n",
    "\n",
    "system_message = \"You are a helpful airline agent. You are given a question and you need to answer it.\" \n",
    "system_message += \"You are not allowed to say that you are an AI assistant.\"\n",
    "system_message += \"If you do not know the answer, just say you don't know\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"What is the ticket price for Tokyo?\"})\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "## Step-5 Define a function on how to handle tool call\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    if tool_name == \"get_ticket_price\":\n",
    "        city = tool_args.get(\"destination_city\",\"unknown\")\n",
    "        price = get_ticket_price(city)\n",
    "    \n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": f\"The ticket price for {tool_args.get('destination_city')} is {price}\",\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response,city\n",
    "    \n",
    "def get_ticket_price(destination_city):\n",
    "    return ticket_prices.get(destination_city.strip().lower(),\"unknown\")\n",
    "\n",
    "#Step-6 Handle if the response of LLM finishes with a tool_call\n",
    "\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "    message = response.choices[0].message\n",
    "    response,city = handle_tool_call(message)\n",
    "    messages.append(message)\n",
    "    messages.append(response)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"I want to go from New Delhi to Mumbai\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for entity in doc.ents:\n",
    "   if entity.label_ == 'GPE':\n",
    "      print(entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'metadata': None, 'content': 'Hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello! How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'I would like to go to Mumbai', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Great choice! Could you please provide me with the departure city or airport, so I can help you with ticket information?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'IAD', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"I'm sorry, but I couldn't find the ticket price for a flight from IAD to Mumbai at this moment. If you have any other questions or need assistance with something else, feel free to ask!\", 'options': None}, {'role': 'user', 'content': 'Can you check again'}]\n",
      "{'destination_city': 'Mumbai', 'price': 500}\n"
     ]
    }
   ],
   "source": [
    "import duckdb as dd\n",
    "\n",
    "conn = dd.connect(\"ticket_price.db\")\n",
    "conn.execute(\"CREATE or REPLACE TABLE ticket_prices (city VARCHAR, price INT)\")\n",
    "conn.execute(\"INSERT INTO ticket_prices VALUES ('London', 100), ('Paris', 200), ('Tokyo', 300), ('Sydney', 400), ('Mumbai',500)\")\n",
    "result = conn.execute(f\"SELECT price FROM ticket_prices WHERE city = '{city}'\").df()\n",
    "print(result['price'].iloc[0])\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve information from DB to set the right context for LLM using function call.\n",
    "\n",
    "import duckdb as dd\n",
    "\n",
    "\n",
    "def get_ticket_price(city):\n",
    "    conn = dd.connect(\"ticket_price.db\")\n",
    "    result = conn.execute(f\"SELECT price FROM ticket_prices WHERE city = '{city}'\").df()\n",
    "    if result.empty:\n",
    "        response = {\"destination_city\": city, \"price\": \"unknown\"}\n",
    "    else:\n",
    "        response = {\"destination_city\": city, \"price\": int(result['price'].iloc[0])}\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "price_function = {\"name\": \"get_ticket_price\", \n",
    "                  \"description\": \"Get the ticket price for a destination city\", \n",
    "                  \"parameters\": {\n",
    "                      \"type\": \"object\",\n",
    "                      \"properties\": {\n",
    "                          \"destination_city\": {\"type\": \"string\", \"description\": \"The destination city\"},\n",
    "                      },\n",
    "                      \"required\": [\"destination_city\"],\n",
    "                      \"additionalProperties\": False\n",
    "                  }\n",
    "                  } \n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    city = tool_args.get(\"destination_city\")\n",
    "    if tool_name == \"get_ticket_price\":\n",
    "       response = {\"role\": \"tool\", \n",
    "                   \"content\": json.dumps(get_ticket_price(city)),\n",
    "                   \"tool_call_id\": tool_call.id\n",
    "                   }\n",
    "    else:\n",
    "        response = {\"role\": \"tool\", \n",
    "                    \"content\": json.dumps({\"destination_city\":\"unknown\", \"price\": \"unknown\"}),\n",
    "                    \"tool_call_id\": tool_call.id \n",
    "                    }\n",
    "    return response, city\n",
    "\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "def chat(history):\n",
    "    system_message = \"You are a helpful airline agent. You are given a question and you need to answer it.\" \n",
    "    system_message += \"You are not allowed to say that you are an AI assistant.\"\n",
    "    system_message += \"If you do not know the answer, just say you don't know\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    messages.extend(history)\n",
    "    message = history[-1][\"content\"]\n",
    "    \n",
    "    #destination_city = extract_city(message)\n",
    "\n",
    "    #image = create_image(destination_city) if destination_city != 'unknown' else None    \n",
    "    image = None\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response,city = handle_tool_call(message)\n",
    "        image = create_image(city) \n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "    history += [{\"role\": \"assistant\", \"content\": response.choices[0].message.content}]\n",
    "    return history, image\n",
    "\n",
    "\n",
    "\n",
    "# Now setup gradio UI\n",
    "\n",
    "with gr.Blocks() as UI:\n",
    "    gr.Markdown(\"Airline Agent\")\n",
    "    with gr.Row():\n",
    "       chatbot = gr.Chatbot(height=400, type=\"messages\")\n",
    "       image_output = gr.Image(height=400)\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(placeholder=\"Chat with your Travel Assistant\", label=\"User Input\")\n",
    "\n",
    "    def user_input_handler(message, history):\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        print(history)\n",
    "        return \"\", history\n",
    "\n",
    "    user_input.submit(user_input_handler, \n",
    "                      inputs=[user_input, chatbot], \n",
    "                      outputs=[user_input, chatbot]\n",
    "                      ).then(chat, \n",
    "                             inputs=chatbot, \n",
    "                             outputs=[chatbot, image_output])\n",
    "\n",
    "UI.launch(inbrowser=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
